% Eksamensoppgave i INF5620

\documentclass[a4paper, 10pt]{article}
\usepackage[utf8x]{inputenc}
\usepackage{cancel}
\usepackage{graphicx}
\usepackage{amsmath}
\newcommand{\mb}{\mathbf}
\newcommand{\mc}{\mathcal}
\newcommand{\n}{\nabla}

\author{Henrik Andersen Sveinsson}
\title{Eksamensoppgave 4 - INF5620 \\ \large Finite elements for a 1D wave equation }
\date{\today}


\begin{document}
\maketitle

\section{Oppgavetekst}
 We consider the 1D wave equation problem on $\Omega=[0,L]$:

\begin{equation}
	u_{tt}=c^2u_{xx}+f, \ u(x,0)=I(x), \ u_t(x,0)=0, \ u_x(0)=u_x(L)=0.
\end{equation}

\subsection{a}
Explain how the initial condition can be approximated by the finite element method using the principles of least squares, projection (Galerkin), and interpolation (collocation).

\subsection{b} 
Discretize in time by a centered difference: $u_{tt}(x_i,t_n)\approx[D_t D_tu]^n_i$. Derive a variational formulation of the time-discrete wave equation problem using the Galerkin method. Derive formulas for the element matrix and vector corresponding to the term with $u_{xx}$ in the PDE.

\subsection{c} Show how the element matrix associated with the uxx term is computed for P1 elements. Explain the assembly principle and what the resulting global matrix look like when all cells have equal length.

\subsection{d} Set up the discrete equations for this wave problem on operator form (assume P1 elements). Briefly explain the idea of an analysis of the scheme based on exact solution of the discrete equations. State the main results. Compare the main results with those of the finite difference method (Problem 3: Analysis of wave problems). 

\section{Hvordan legge opp oppgaven?}
Jeg kommer til å bruke mest tid på oppgave b og c, siden disse på sett og vis illustrerer hele elementmetoden, og jeg har fått mye innsikt av å jobbe gruyndig med disse. 

\section{Tilnærming av initialbetingelsen}
\subsection{Interpolasjon (Kolokasjon)}
Ideen med interpolasjon er at den tilnærmede funksjonen skal ha samme verdi som den opprinnelige funksjonen på et endelig sett med punkter $x_i \in \mc{I}_s$:
\begin{equation}
	u(x_i) = \sum_{j\in \mc{I}_s}c_j \psi_j(x_i) = f(x_i), i\in \mc{I}_s
\end{equation}
Vi kan like godt skrive at $\psi_j(x_i) = A_{i,j}$ og $f(x_i) = b_i$, slik at vi får et likningssystem:
\begin{equation}
	\sum_{\mc{I}_s} A_{i,j}c_j = b_i, i\in \mc{I}_s
\end{equation}
Dermed har vi en matriselikning $A\mb{c} = \mb{b}$ som løses for å finne de ukjente koeffisientene $c_j$.
Det finnes sett med funksjoner som er slik at $\psi_i(x_j) = \delta_{i,j}$, slik at matrisen $A$ blir diagonal. 

\subsection{Galerkin (Projeksjon)}
Utgangspunktet er at vi vil tilnærme en funksjon $f$ som:
\begin{equation}
	f(x) \approx u = \sum_{j\in \mc{I}_s} c_j \psi_j
\end{equation}
Der $u \in V$ er den tilnærmede funksjonen.
Prinsippet som skal brukes, er at forskjellen mellom $f$ og $u$ skal være ortogonal på $V$ som inneholder funksjonene vi ekspanderer $f$ i. Dette viser seg å være ekvivalent med minste kvadraters metode. 

Vi kan sette opp: 
\begin{equation}
	e = f - \sum_{j\in \mc{I}_s} c_j \psi_j
\end{equation}
At $e$ er ortogonal på $V$ er det samme som at $(e, v) = 0 \  \forall v \in V$. For vårt spesifikke valg av basisfunksjoner $\psi_j$, får vi:
\begin{equation}
	(e, \psi_i) = 0 \ \forall i \in \mc{I}_s
\end{equation}
Vi setter så inn at $e = f - \sum_{j\in \mc{I}_s} c_j \psi_j$. Det gir at
\begin{equation}
	(f - \sum_{j\in \mc{I}_s} c_j \psi_j, \psi_i), i \in \mc{I}_s
\end{equation}
Vi ser at dette blir 
\begin{equation}
	\sum_{j \in \mc{I}_s} (\psi_j, \psi_i)c_j = (f, \psi_i), i\in \mc{I}_s
\end{equation}

Dette er et lineært likningssett $A\mb{c} = \mb{b}$, som kan løses for $\mb{c}$.
\begin{equation}
	A_{i, j} = (\psi_i, \psi_j)
\end{equation}
\begin{equation}
	b_i = (f, \psi_i)
\end{equation}

For initialbetingelsen spesielt, så setter vi $b_i = I(x_i), i \in \mc{I}_s$.

\subsection{Least Squares}
For minste kvadrater ønsker vi å minimere kvadratet av residualen integrert over domenet:
\begin{equation}
	(R, R)_{min}
\end{equation}
Når vi skriver løsningen vår som en lineærkombinasjon av funksjoner i et funksjonsrom er dette ekvivalent med 
\begin{equation}
	\left( R, \frac{\partial R}{\partial c_i} \right) \ \forall i \in \mc{I}_s
\end{equation}

\section{Tidsdiskretisering og variasjonell formulering}
Vi diskretiserer $u_{tt} = c^2 u_{xx} + f$ med sentrert differanse i tid:
\begin{equation}
	\frac{u^{n+1} - 2 u^n + u^{n-1}}{\Delta t^2} = c^2 u_{xx} + f
\end{equation}
\begin{equation}
	 \mathcal{L}(u) = -u^{n+1} +2u^n - u^{n-1} + c^2 \Delta t^2 (u_{xx} + f) = 0
\end{equation}
Vi har altså en diskret likning i tid, og en kontinuerlig i rom. Vi ønsker nå å tilnærme den romlige løsningen med elementfunksjoner. Da kommer ikke løsningen til å tilfredsstille likningen over, men vi kan lage løsningen slik at den minimerer feilen, nemlig ved å kreve at feilen står ortogonalt på rommet vi utspenner løsningen i.

Vi tenker nå at $u = \sum_{j \in \mc{I}_s} c_j \psi_j$, altså at $u$ er utspent i et rom $V = \mbox{span}\{\psi_1, ..., \psi_N\}$

Vi setter altså at:
\begin{equation}
	R = \mathcal{L}(u)
\end{equation}
og krever at
\begin{equation}
	(R, v) = 0, \ \forall v \in V
\end{equation}
som er variasjonsformuleringen.

Vi skriver nå om likningen til ny tidsnotasjon: $u \equiv u^{n+1}$, $u_1 \equiv u^n$, $u_2 \equiv u^{n-1}$.

Da ser variasjonsformuleringen vår ut som dette:
\begin{equation}
(u, v) = 2(u_1, v) - (u_2, v) + c^2\Delta t^2\left[(u_{1, xx}, v) + (f, v)\right]
\end{equation}

Så er vi ikke så glade i å derivere løsningene våre to ganger, så vi delvis integrerer den dobbelderiverte, noe som gir oss en naturlig måte å takle grensebetingelser på.

Delvis integrasjonen gir
\begin{equation}
	\int_0^L u_{xx} v \ dx = [u_xv]_0^L - \int_0^L u_xv_x \ dx
\end{equation}
Vi ser at $[u_xv]_0^L = 0$ siden grensebetingelsene er $u_x(0) = u_x(L) = 0$.
Dermed blir varisjonsformuleringen:
\begin{equation}
	(u, v) = 2(u_1, v) - (u_2, v) + c^2\Delta t^2\left[(u_{1,x}, v_x) + (f, v)\right]
\end{equation}

Vi setter så inn den faktiske ekspansjonen av $u$:
\begin{equation}
	\sum_{j \in \mc{I}_s } (\psi_j, \psi_i)c_j = 2\sum_{j \in \mc{I}_s }(\psi_j, \psi_i)c_{1, j} - \sum_{j \in \mc{I}_s }(\psi_j, \psi_i)c_{2, j} + c^2\Delta t^2 \left[\sum_{j \in \mc{I}_s } (\psi_j', \psi_i')c_{1, j} + (f, \psi_i)\right]
\end{equation}

Vi ser så nærmere på leddet som kommer fra $u_{xx}$, nemlig $\sum_{j \in \mc{I}_s } (\psi_j', \psi_i')c_{1, j}$. 
Dette leddet er i prinsippet en matrise og en vektor, slik at 
\begin{equation}
	A_{i, j} = \int_0^L \psi_j'(x)\psi_i'(x) \ dx
\end{equation}
Dette er formelen for elementene i den globale matrisen. Så går vi over til enkeltelementer av typen $P1$.
For ordens skyld skifter vi til elementbasisfunksjoner og integrerer over et referanseelement
\begin{equation}
	\tilde{A}_{i, j} = \int_0^L \tilde{\varphi}_j'(X)\frac{dX}{dx}\tilde{\varphi}_i'(X)\frac{dX}{dx} \ \frac{dx}{dX} dX
\end{equation}

Her har vi tatt med jacobideterminanten $\frac{dx}{dX}$ og kjerneregelen på de deriverte elementfunksjonene. 

P1-funksjoene på hver element er
\begin{equation}
	\tilde{\phi}_0(X)=\frac{1}{2}(1-X),\quad\tilde{\phi}_1(X)=\frac{1}{2}(1+X),
\end{equation}

For $P1$-elementer $[-1, 1]$ er $\frac{dx}{dX} = h$.

Det betyr at en elementmatrise blir:
\begin{equation}
\tilde{A}^{(e)} =\frac{1}{h}\left[	
\begin{array}{cc}
1 & -1 \\
-1 & 1 
\end{array}
\right]
\end{equation}

\section{Assemblering}
Elementene vi jobber med har overlappende noder. Dersom vi antar at vi har regulær nummerering av nodene setter vi nå sammen den globale matrisen ved å la hjørnene på elementmatrisene overlappe langs hoveddiagonalen. 

Den resulterende matrisen er $[-1 \ 2 \ -1]$ repeterende, med noen endringer ved randbetingelsene. Vi vil typisk bruke en randfunksjon for å inkorporere randbetingelser, og denne innføres ved å endre likningssystemet etterpå. Vi kan gjøre endringen symmetrisk ved å gjøre noen radoperasjoner på matrisen etterpå.

\section{Sammenlikning med finite difference}
Hovedtanken når vi sammenlikner med finite difference er å plukke ut den i'te raden i matriselikningen vi løser og skrive det om med differanseoperatorer. 
Vi forholder oss fortsatt til likningen
\begin{equation}
	\sum_{j \in \mc{I}_s } (\psi_j, \psi_i)c_j = 2\sum_{j \in \mc{I}_s }(\psi_j, \psi_i)c_{1, j} - \sum_{j \in \mc{I}_s }(\psi_j, \psi_i)c_{2, j} + c^2\Delta t^2 \left[\sum_{j \in \mc{I}_s } (\psi_j', \psi_i')c_{1, j} + (f, \psi_i)\right]
\end{equation}

For å gjøre ting mer håndterbart skriver vi den på matriseform.
Vi definerer oss følgende:
\begin{itemize}
\item $K = \{\sum (\psi_i', \psi_j')\}$
\item $M = \{\sum (\psi_i, \psi_j)\}$
\item $\mb{f} = \{(f, \psi_i)\}$
\end{itemize}

\begin{equation}
	M\mb{c} = 2M\mb{c}_1 - M\mb{c_2} + c^2\Delta t^2 (K\mb{c}_1 + \mb{f})
\end{equation}
Vi ønsker nå å skrive dette tilbake til et format som er sammenliknbart med endelige differanser, for å se hvilke modifikasjoner vi har gjort i forhold til den metoden.

Vi vet at $K-matrisen$ anvendt på forrige sett med P1-koeffisienter tilsvarer en standard sentrert differanseoperator.
\begin{equation}
Kc_i^n = [D_x D_x u]_i^n
\end{equation}
Så vet vi tilsvarende om $M$-matrisen
\begin{equation}
	Mc_i^n = [u-\frac{1}{6}h^2 D_x D_x u]_i^n
\end{equation}

Dette lar oss skrive hele den diskrete likningen som
\begin{equation}
	\left[u-\frac{1}{6} h^2 D_xD_x u\right]_i^{n+1} = 2\left[u-\frac{1}{6} h^2 D_xD_x u\right]_i^n - \left[u-\frac{1}{6} h^2 D_xD_x u\right]_i^{n-1} + c^2 \Delta t^2 \left[D_xD_xu\right]_i^n
\end{equation}
Vi ser bort ifra driveleddet f akkurat nå, for enkelhets skyld. Dersom vi nå deler på $\Delta t^2$, og flytter de tre like parentesene til venstre side, ser vi at vi har en sentrert differanse i tid av hele parentesen:
\begin{equation}
	D_tD_t\left[u-\frac{1}{6} h^2 D_xD_x u\right]_i^n = c^2[D_xD_xu]_i^n
\end{equation}

\subsection{Stabilitet og fasefeil}
Vi vil se på løsningene av de diskrete likningene. Da kommer vi til å få ledd som setter krav på parametrene vi setter inn. Vi vil også se på forskjellen mellom bølgehastighet i den kontinuerlige og numeriske løsningen, for å analysere rippler i løsningen. Det viser seg at for at dette skjemaet skal være stabilt må 
\begin{equation}
	C \leq \frac{1}{\sqrt{3}}
\end{equation}
Dette kan sammenliknes med kriteriet i den vanlige finite difference approsimasjonen der $C \leq 1$

Vi mister den fantastiske egenskapen at vi kan sette Couranttallet til 1 og få en eksakt løsning. 

Vi kan også se på $\frac{\tilde{c}}{c}$ for finite element og finite difference, og se at i finite element har en annerledes dispersjonsrelasjon enn finite difference. 


\end{document}